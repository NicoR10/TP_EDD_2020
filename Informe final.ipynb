{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRABAJO PRÁCTICO FINAL - ESTRUCTURAS DE DATOS\n",
    "### GRUPO: Yarará\n",
    "\n",
    "#### Integrantes:\n",
    "- Eduardo Reichel\n",
    "- Liber Rosetti\n",
    "- Nicolás Racedo\n",
    "- Matías Correa\n",
    "\n",
    "#### Enlace al video explicativo:\n",
    "[TP YARARÁ](https://www.youtube.com/watch?v=8ipaxdeOUaU&ab_channel=EduardoEmanuelReichel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFORME\n",
    "\n",
    "En el contexto de la materIa Estructuras de datos de la carrera Ingeniería de Computación, se presenta el trabajo integrador de la misma.\n",
    "El trabajo consiste en un programa diseñado en Python que compara los precios de productos de distintas páginas y los devuelve en un archivo de formato de salida específico.\n",
    "\n",
    "La estructura del informe esta organizado en análisis de las páginas selecionadas, diagramas de clase y decisiones de diseño. \n",
    "\n",
    "Para poder ejectuar el programa, es necesario que el usuario tenga instalada ciertas librerias, que se detallan a continuación:\n",
    "- SCRAPY\n",
    "- NLTK (se debe descargar dos paquetes que el programa te indica)\n",
    "- JSONPICKLE\n",
    "\n",
    "Se destaca que el programa fue testeado en distintos sistemas operativos:\n",
    "- Windows 10\n",
    "- Linux Ubuntu 20.04 LTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIAGRAMAS DE CLASE\n",
    "\n",
    "En la siguiente imagen se puede observar el diagrama de clases del proyecto:\n",
    "\n",
    "<img src=\"uml.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISIONES DE DISEÑO\n",
    "\n",
    "A continuación se explican las decisiones de diseño que se tomaron en cuenta para el trabajo.\n",
    "En primer lugar, al elegir las páginas para analizar, se decidió escrapear toda la página entera, por categorías de productos. Por esto nos referimos a que al ejecutar el programa, el mismo va página por página analizando cada una de las categorías y cada uno de los productos. Esto fue porque no todas las páginas tenian URL con Jquery para realizar la búsqueda de productos y por otro lado, buscamos que todas las páginas tengan una misma estructura para no generar técnicas de escrapeo distintas.\n",
    "\n",
    "Con respecto al menú, esta diseñado para que el usuario avance por las distintas opciones ingresando números que hacen referencia a las distintas opciones. Se aclara que al ejecutar el programa, si el usuario ingresa el número \"1\", el programa llega a su fin.\n",
    "\n",
    "En los spiders, se utilizó la clase Items con el objetivo de organizar el formato de salida de los elementos de buscados.\n",
    "\n",
    "Se decidió que la información de salida (los archivos que se pueden obtener Json, HTML, CSV) se almacenan en una carpeta del proyecto que se llama \"Resultados\". Se toma el path desde la dirección donde se está corriendo el programa y en caso de que no esté creada la carpeta \"Resultados\", la crea.\n",
    "\n",
    "Como archivo de configuración, se creó el archivo \"config.py\". En el mismo se detallan las páginas, formatos admitidos de salida, tipos de busqueda, las start URL y los métodos get de cada uno de los tipos.\n",
    "\n",
    "Se decidió utilizar CrawlerProcess para poder corres los spiders. Con esta herramienta se logró poder ejecutar cada uno de los spiders en paralelo. Durante el desarrollo, se intentó implementar Reactor, pero al utilizarlo se encontraron inconvenientes durante la ejecución y se optó por otra opción.\n",
    "\n",
    "Para los items opcionales, se tuvieron dos consideraciones:\n",
    "\n",
    "- Por un lado, en caso de que los productos no tuviesen precio, se decidió que el precio del producto va a ser igual a cero.\n",
    "- Por otro lado, en cuanto al item que solicita ordenar los productos de una busqueda que ingrese el usuario, nos encontramos con el problema de que un mismo producto; en distintas páginas, puede tener un nombre distinto. \n",
    "\n",
    "Ejemplo:\n",
    "   - **Celular Libre Samsung Galaxy S20 Ultra Gris** (Fravega)\n",
    "   - **Celular Libre Samsung S20 6.2\" 8/128 Gris** (Casa Del Audio)\n",
    "   - **CELULAR LIBRE SAMSUNG S20 ULTRA GRIS** (Cetrogar)\n",
    "\n",
    "Para poder solucionar esto, se implementó la librería difflib. Esta librería analiza el porcentaje de exactitud entre distintas frases. Es necesario setear un escalar que me define el nivel de exactitud que quiero obtener. Cero significa que no se quiere exactitud, 1 significa que la búsqueda tiene que ser completamente exacta. Optamos tomar por un valor de 0.8 en base a pruebas empíricas. Se probó tomar un valor de 1 pero ninguna de las páginas tiene el mismo nombre en cada producto.\n",
    "\n",
    "Para la página de Musimundo, nos encontramos que al buscar los precios de los productos, la página devolvía dos precios distintos dependiendo de donde lo busque, como se ve en la siguiente imagen:\n",
    "\n",
    "<img src=\"musimundo_precios.png\">\n",
    "\n",
    "\n",
    "Decidimos en este caso, quedarnos con el de menor valor, ya que era del mismo lugar de donde recuperamos los precios de los demás productos.\n",
    "\n",
    "Por último, se encontró que a lo largo del código se repetían varías secciones en la lógica utilizada por los spider para definir, según los tipos de búsqueda, si es válido el producto encontrado. Para eso, se implemento una clase \"utils.py\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANÁLISIS DE LAS PÁGINAS\n",
    "\n",
    "Se decidió trabajar con páginas de electrodomésticos que funcionen a nivel nacional. El primer listado de páginas que se pensó fue el siguiente:\n",
    "\n",
    "- [Frávega](https://www.fravega.com/)\n",
    "- [Musimundo](https://www.musimundo.com/)\n",
    "- [Cetrogar](https://www.cetrogar.com.ar/)\n",
    "- [Rodo](https://www.rodo.com.ar/)\n",
    "- [Casa Del Audio](https://www.casadelaudio.com/)\n",
    "- [Carrefour](https://www.carrefour.com.ar/)\n",
    "- [Falabella](https://www.falabella.com.ar/falabella-ar/)\n",
    "- [Garbarino](https://www.garbarino.com)\n",
    "- [Grupo Marquez](https://grupomarquez.com.ar/)\n",
    "\n",
    "\n",
    "En este punto, lo primero que se analizó fue si cada unas de estas páginas podía ser scrapeada. \n",
    "Para eso, se ejecutaron los siguientes comandos por consola para analizar lo antes mencionado:\n",
    "    \n",
    "    scrapy shell \"URL\"\n",
    "    \n",
    "En los casos de páginas que nos retornan por consola la siguiente linea:\n",
    "\n",
    "   [scrapy.core.engine] DEBUG: Crawled (200) <GET URL>\n",
    "    \n",
    "interpretamos que vamos a poder scrapear la página y traernos la información que deseamos.\n",
    "Se encontró dos inconvenientes a la hora de seleccionar las páginas. \n",
    "Por un lado, por ejemplo en la página de Rodo y Garbarino, al ejecutar el siguiente comando\n",
    "    scrapy shell \"www.rodo.com.ar\"\n",
    "\n",
    "Se obtuvo lo siguiente:\n",
    "\n",
    "[scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://rodo.com.ar/> from <GET https://www.rodo.com.ar/productos.html>\n",
    "\n",
    "Esto nos indica que la página no puede ser scrapeada.\n",
    "Otra página con la que tuvimos problema fue garbarino, que al querer analizar si se puede scrapear nos devolvió la siguientes lineas:\n",
    "\n",
    "    [scrapy.core.engine] DEBUG: Crawled (403) <GET https://www.garbarino.com:443/> (referer: None)\n",
    "    [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.garbarino.com:443/> from <GET http://www.garbarino.com>\n",
    "    \n",
    "Por otro lado, ciertas páginas estan realizadas con frameworks relativamente nuevos (EJ: React), que hace que la página sea dinámica y no se pueda acceder a todos los productos de una vez. En esos casos, se descartaron las páginas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las 4 páginas que finalmente seleccionamos para el trabajo fueron:\n",
    "\n",
    "   - [Frávega](https://www.fravega.com/)\n",
    "   - [Cetrogar](https://www.cetrogar.com.ar/)\n",
    "   - [Casa Del Audio](https://www.casadelaudio.com/)\n",
    "   - [Musimundo](https://www.musimundo.com/)\n",
    "  \n",
    "Como aclaramos anteriormente, lo que hicimos fue buscar páginas que se recorrieran de la misma manera. Es decir, páginas que tuvieran un elemento que tuviera cada una de las categorías que ofrecian y de cada categoría recorer cada uno de los productos.\n",
    "En la siguiente imagen se puede observar un ejemplo con cetrogar\n",
    "\n",
    "\n",
    "<img src=\"cetrogar_categorias.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El recorrido de la página se analizó utilizando xpath y buscando los elementos que van desde el inicio de la página hasta el listado de productos. En la imagen que sigue se puede ver un ejemplo:\n",
    "\n",
    "\n",
    "<img src=\"cetrogar_xpath.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, el inconveniente que se presentaba era como acceder a los productos que se encuentren en otras páginas.\n",
    "En todas las que utilizamos, encontramos que tiene un boton de \"next\" el cual está asociado a un link mediante la propiedad href. \n",
    "\n",
    "De cada uno de los productos, lo que recuperamos fue el precio, el nombre completo, la categoría del producto y la fecha en la que se busca el producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from menu import Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = Menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu.ejecutar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Los archivos han sido creados en una carpeta llamada \"Resultados\" en el path donde se está ejecutando este documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "from utils import Utils\n",
    "from procesador import Procesador\n",
    "from os import path\n",
    "import pathlib\n",
    "import datetime\n",
    "from config import Config\n",
    "import menu\n",
    "from menu import QuiereSalirException\n",
    "import unittest\n",
    "from unittest.mock import patch\n",
    "\n",
    "utils = Utils()\n",
    "def test_tipo_busqueda_1():\n",
    "    '''Publicación con la frase exacta'''\n",
    "    target = 'Lavarropas Carga Frontal Longvie 8 Kg 1200 RPM L18012'\n",
    "    title = 'Lavarropas Carga Frontal Longvie 8 Kg 1200 RPM L18012'\n",
    "    assert utils.tipo_busqueda_1(target, title)\n",
    "\n",
    "def test_tipo_busqueda_2():\n",
    "    '''Publicación que contenga todas las palabras'''\n",
    "    target = 'Lavarropas Carga Frontal Longvie 8 Kg 1200 RPM L18012'\n",
    "    title = 'Lavarropas Carga Frontal Longvie 8 Kg 1200 RPM L18012'\n",
    "    assert utils.tipo_busqueda_2(target, title)\n",
    "\n",
    "def test_tipo_busqueda_2_v1():\n",
    "    '''Publicación que contenga todas las palabras'''\n",
    "    target = 'Lavarropas CARGA Frontal'\n",
    "    title = 'Lavarropas Carga Frontal Longvie 8 Kg 1200 RPM L18012'\n",
    "    assert utils.tipo_busqueda_2(target, title)\n",
    "\n",
    "def test_tipo_busqueda_3():\n",
    "    '''Publicación que contenga algunas de las palabras.'''\n",
    "    target = 'Lavarropas Longvie'\n",
    "    title = 'Lavarropas Carga Frontal Longvie 8 Kg 1200 RPM L18012'\n",
    "    assert utils.tipo_busqueda_3(target, title)\n",
    "\n",
    "def test_tipo_busqueda_3_v1():\n",
    "    '''Publicación que contenga todas las palabras'''\n",
    "    target = 'Celular Samsung'\n",
    "    title = 'CELULAR LIBRE SAMSUNG S20 ULTRA GRIS'\n",
    "    assert utils.tipo_busqueda_3(target, title)\n",
    "\n",
    "#fragmeto extraido de un scrapeo donde criterio fue longvie, pero para lo cambio a restados_test para test\n",
    "lista = [{'categoria': 'Electrodomésticos','fecha': '15/11/2020 12:26:02',\n",
    " 'link': 'https://www.cetrogar.com.ar/aspiradora-electrolux-gt30n-1300w.html',\n",
    " 'market': 'cetrogar', 'price': 12109.0,\n",
    " 'title': 'Calefactor Longvie EC3200ECA3 Con Multigas'}, {'categoria': 'Electrodomésticos',\n",
    " 'fecha': '15/11/2020 12:26:07',\n",
    " 'link': 'https://www.cetrogar.com.ar/aspiradora-yelmo-as-3228-2000w-sin-bolsa.html',\n",
    " 'market': 'cetrogar', 'price': 23899.0,\n",
    " 'title': 'Termotanque Longvie Electrico para colgar TE40F Carga Inferior'}, {'categoria': 'Electrodomésticos',\n",
    " 'fecha': '15/11/2020 12:26:07',\n",
    " 'link': 'https://www.cetrogar.com.ar/cafetera-nespressor-inissia-red-aeroccino-3-a3c40-ar-re-ne.html',\n",
    " 'market': 'cetrogar', 'price': 29999.0,\n",
    " 'title': 'Termotanque Longvie Multigas Colgar 50 Litros inferior'}, {'categoria': 'Electrodomésticos',\n",
    " 'fecha': '15/11/2020 12:26:08',\n",
    " 'link': 'https://www.cetrogar.com.ar/microondas-bgh-qchef-28l-b228db-bl.html',\n",
    " 'market': 'cetrogar', 'price': 43799.0,\n",
    " 'title': 'Lavarropas Longvie L16508 6.5Kg 800rpm'}, {'categoria': 'Electrodomésticos',\n",
    " 'fecha': '15/11/2020 12:26:08',\n",
    " 'link': 'https://www.cetrogar.com.ar/anafe-longvie-a-6600g-x-4-hornallas-gas.html',\n",
    " 'market': 'cetrogar', 'price': 48999.0, 'title': 'Anafe Longvie A-6600G x 4 Hornallas Gas'}]\n",
    "\n",
    "criterio = 'resultados test'.replace(' ','_')\n",
    "procesador = Procesador(lista, criterio)\n",
    "\n",
    "def test_imprimir_archivo_csv():\n",
    "    procesador.imprimirArchivo('csv')\n",
    "    filename = criterio + \"_\" + datetime.datetime.now().strftime(\"%d-%m-%Y\") + '.csv'\n",
    "    assert path.isfile('resultados/' + filename)\n",
    "\n",
    "def test_imprimir_archivo_json():\n",
    "    procesador.imprimirArchivo('json')\n",
    "    filename = criterio + \"_\" + datetime.datetime.now().strftime(\"%d-%m-%Y\") + '.json'\n",
    "    assert path.isfile('resultados/' + filename)\n",
    "\n",
    "def test_imprimir_archivo_html():\n",
    "    procesador.imprimirArchivo('html')\n",
    "    filename = criterio + \"_\" + datetime.datetime.now().strftime(\"%d-%m-%Y\") + '.html'\n",
    "    assert path.isfile('resultados/' + filename)\n",
    "\n",
    "config = Config()\n",
    "def test_config_paginas():\n",
    "    assert config.get_paginas()['5'] == 'Todas'\n",
    "\n",
    "def test_config_formatos_admitidos():\n",
    "    assert config.get_formatos_admitidos()['2'] == 'json'\n",
    "\n",
    "def test_config_tipos():\n",
    "    assert config.get_tipos()['3'] == 'Alguna de las palabras'\n",
    "\n",
    "def test_config_url():\n",
    "    assert config.get_start_url()['fravega'] == 'https://www.fravega.com/'\n",
    "\n",
    "def test_config_extras():\n",
    "    assert config.get_extras()['1'] == 'Estadísticas por modelo'\n",
    "\n",
    "#Test de Menu\n",
    "class TestMenu(unittest.TestCase):\n",
    "    \n",
    "    menu_t = menu.Menu()\n",
    "    \n",
    "    # Test para formato '1'\n",
    "    @patch(\"builtins.input\", return_value=\"1\")\n",
    "    def test_pedir_formato_1(self, mock_input):\n",
    "        self.assertEqual(self.menu_t._Menu__pedir_formato(), \"1\")\n",
    "        \n",
    "    # Test para input '0' (Quiere salir)\n",
    "    @patch(\"builtins.input\", return_value=\"0\")\n",
    "    def test_pedir_formato_0(self, mock_input):\n",
    "        with self.assertRaises(QuiereSalirException):\n",
    "            self.menu_t._Menu__pedir_formato()\n",
    "            \n",
    "    # Test para formato pedir pagina\n",
    "    @patch(\"builtins.input\", return_value=\"3\")\n",
    "    def test_pedir_pagina_3(self, mock_input):\n",
    "        self.assertEqual(self.menu_t._Menu__pedir_pagina(), [\"3\"])\n",
    "        \n",
    "    # Test para formato pedir varias paginas\n",
    "    @patch(\"builtins.input\", return_value=\"3,1,2\")\n",
    "    def test_pedir_paginas(self, mock_input):\n",
    "        self.assertEqual(self.menu_t._Menu__pedir_pagina(), [\"3\", '1', '2'])\n",
    "        \n",
    "    # Test para input '0' (Quiere salir)\n",
    "    @patch(\"builtins.input\", return_value=\"0\")\n",
    "    def test_pedir_pagina_0(self, mock_input):\n",
    "        with self.assertRaises(QuiereSalirException):\n",
    "            self.menu_t._Menu__pedir_pagina()\n",
    "    \n",
    "    # Test para formato pedir tipo busqueda\n",
    "    @patch(\"builtins.input\", return_value=\"2\")\n",
    "    def test_pedir_tipo_busqueda(self, mock_input):\n",
    "        self.assertEqual(self.menu_t._Menu__tipo_busqueda(), '2')\n",
    "        \n",
    "    # Test para input '0' (Quiere salir)\n",
    "    @patch(\"builtins.input\", return_value=\"0\")\n",
    "    def test_pedir_tipo_busqueda_0(self, mock_input):\n",
    "        with self.assertRaises(QuiereSalirException):\n",
    "            self.menu_t._Menu__tipo_busqueda()\n",
    "            \n",
    "    # Test para formato pedir extras\n",
    "    @patch(\"builtins.input\", return_value=\"2\")\n",
    "    def test_pedir_extra_2(self, mock_input):\n",
    "        self.assertEqual(self.menu_t._Menu__pedir_extras(), '2')\n",
    "        \n",
    "    # Test para input '0' (Quiere salir)\n",
    "    @patch(\"builtins.input\", return_value=\"0\")\n",
    "    def test_pedir_extra_0(self, mock_input):\n",
    "        with self.assertRaises(QuiereSalirException):\n",
    "            self.menu_t._Menu__pedir_extras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
